{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lcruz\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "import pandas as pd\n",
    "import re\n",
    "import pkg_resources\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "import nltk\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Muri√≥ una mujer de 99 a√±os por el coronavirus....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#GOPIdiots is correct https://t.co/QBrncMW2VL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Only took 5 https://t.co/1h0tqHaAZX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @NewDay: Japan‚Äôs infection rate is under sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @MyFavsTrash: This is the most Florida twee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "0  Muri√≥ una mujer de 99 a√±os por el coronavirus....\n",
       "1      #GOPIdiots is correct https://t.co/QBrncMW2VL\n",
       "2                Only took 5 https://t.co/1h0tqHaAZX\n",
       "3  RT @NewDay: Japan‚Äôs infection rate is under sc...\n",
       "4  RT @MyFavsTrash: This is the most Florida twee..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df = pd.read_pickle(\"tweets2.pkl\")\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252000, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceRT(tweet):\n",
    "    return(tweet.replace(\"RT\", \"\"))\n",
    "\n",
    "\n",
    "\n",
    "links_regex = re.compile(r'http\\S+')\n",
    "def replaceLinks(tweet):\n",
    "    \n",
    "    return(re.sub(links_regex, '', tweet))\n",
    "\n",
    "\n",
    "twitter_regex = re.compile(r'(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9-_]+)')\n",
    "def replaceHandle(tweet):\n",
    "    \n",
    "    return(re.sub(twitter_regex, '', tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>: This video is \"manipulated\" to make it seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>: As the coronavirus spreads globally, packed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>: Did u forget to mention Sen Feinstein‚Äôs ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>They rubber stamped China's lies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>:  How much more fascist can Johnson get - im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>: Wait sooo... the left considers Greta Thunb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>: Luego de ver este video que contradice todo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>: Cancelling play day ...What‚Äôs up ..You guys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Better seat beside Dusbin instead to sit besid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>: This is the proposed coronavirus bill. Seem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet\n",
       "0     : This video is \"manipulated\" to make it seem...\n",
       "1     : As the coronavirus spreads globally, packed...\n",
       "2     : Did u forget to mention Sen Feinstein‚Äôs ins...\n",
       "3                     They rubber stamped China's lies\n",
       "4     :  How much more fascist can Johnson get - im...\n",
       "..                                                 ...\n",
       "495   : Wait sooo... the left considers Greta Thunb...\n",
       "496   : Luego de ver este video que contradice todo...\n",
       "497   : Cancelling play day ...What‚Äôs up ..You guys...\n",
       "498  Better seat beside Dusbin instead to sit besid...\n",
       "499   : This is the proposed coronavirus bill. Seem...\n",
       "\n",
       "[500 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df['tweet'] = tweets_df['tweet'].apply(lambda x: replaceRT(x))\n",
    "tweets_df['tweet'] = tweets_df['tweet'].apply(lambda x: replaceHandle(x))\n",
    "tweets_df['tweet'] = tweets_df['tweet'].apply(lambda x: replaceLinks(x))\n",
    "tweets_sampled = tweets_df.sample(500)\n",
    "tweets_sampled = tweets_sampled.reset_index(drop=True)\n",
    "tweets_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lcruz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords.extend(['coronavirus', 'Koronavirus', 'trump', 'covid-19', 'corona', 'covid', \n",
    "                  'covid19', 'covd', 'virus', 'pandemic', 'chinese', 'china', 'wuhan', 'ncov'])\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in stopwords:\n",
    "            result.append(stemmer.stem(token))\n",
    "            \n",
    "    combined_result = ' '.join(result) ###### this is what i changed from your code, devina ######\n",
    "    return combined_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This tweet throws an error:  : ‡¨ï‡¨∞‡≠ã‡¨®‡¨æ ‡¨Æ‡≠Å‡¨ï‡¨æ‡¨¨‡¨ø‡¨≤‡¨æ : ‡¨è‡¨™‡≠ç‡¨∞‡¨ø‡¨≤ ‡≠©‡≠¶ ‡¨Ø‡¨æ‡¨è‡¨Å ‡¨¨‡¨¢‡¨ø‡¨≤‡¨æ ‡¨≤‡¨ï‡¨°‡¨æ‡¨â‡¨® ‡¨Ö‡¨¨‡¨ß‡¨ø, ‡¨∏‡¨∞‡¨ï‡¨æ‡¨∞‡¨ô‡≠ç‡¨ï ‡¨®‡¨ø‡¨∑‡≠ç‡¨™‡¨§‡≠ç‡¨§‡¨ø‡¨ï‡≠Å ‡¨®‡≠á‡¨á ‡¨Ü‡¨™‡¨£‡¨ô‡≠ç‡¨ï ‡¨Æ‡¨§ ‡¨ï‡¨£? #OdishaFightsCoronaVirus \n",
      "#COVID1‚Ä¶\n",
      "This tweet throws an error:  \n",
      "This tweet throws an error: üò∂\n",
      "This tweet throws an error:  \n",
      "This tweet throws an error:  : \n",
      "This tweet throws an error: ????! \n"
     ]
    }
   ],
   "source": [
    "processed_tweets = []\n",
    "indexesToRemove = []\n",
    "\n",
    "for index, tweet in enumerate(tweets_sampled.tweet.tolist()):\n",
    "    \n",
    "    try:\n",
    "        lang = detect(tweet)\n",
    "        if lang == 'en':\n",
    "            processed_tweets.append(preprocess(tweet))\n",
    "        if lang != 'en':\n",
    "            removeIndex = index\n",
    "            indexesToRemove.append(removeIndex)\n",
    "            \n",
    "    except:\n",
    "        removeIndex = index\n",
    "        indexesToRemove.append(removeIndex)\n",
    "        language = \"error\"\n",
    "        print(\"This tweet throws an error:\", tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308\n"
     ]
    }
   ],
   "source": [
    "tweets_sampled_new = tweets_sampled.drop(tweets_sampled.index[indexesToRemove])\n",
    "print(len(processed_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308, 3913)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the vectorizer object will be used to transform text to vector form\n",
    "vectorizer = TfidfVectorizer(max_df=0.95, ngram_range = (1,2), token_pattern='\\w+|\\$[\\d\\.]+|\\S+')\n",
    "# apply transformation\n",
    "tf = vectorizer.fit_transform(processed_tweets) #.toarray()\n",
    "# tf_feature_names tells us what word each column in the matric represents\n",
    "tf_feature_names = vectorizer.get_feature_names()\n",
    "tf.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_topics = 10\n",
    "model = NMF(n_components=number_of_topics, random_state=45) # random state for reproducibility\n",
    "# Fit data to model\n",
    "nmf_output = model.fit_transform(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 0</th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Word 3</th>\n",
       "      <th>Word 4</th>\n",
       "      <th>Word 5</th>\n",
       "      <th>Word 6</th>\n",
       "      <th>Word 7</th>\n",
       "      <th>Word 8</th>\n",
       "      <th>Word 9</th>\n",
       "      <th>Word 10</th>\n",
       "      <th>Word 11</th>\n",
       "      <th>Word 12</th>\n",
       "      <th>Word 13</th>\n",
       "      <th>Word 14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic 0</th>\n",
       "      <td>test</td>\n",
       "      <td>posit</td>\n",
       "      <td>test posit</td>\n",
       "      <td>tiger</td>\n",
       "      <td>tiger test</td>\n",
       "      <td>british</td>\n",
       "      <td>announc</td>\n",
       "      <td>british member</td>\n",
       "      <td>member parliament</td>\n",
       "      <td>parliament test</td>\n",
       "      <td>break british</td>\n",
       "      <td>parliament</td>\n",
       "      <td>member</td>\n",
       "      <td>first</td>\n",
       "      <td>get</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 1</th>\n",
       "      <td>lockdown</td>\n",
       "      <td>day</td>\n",
       "      <td>day lockdown</td>\n",
       "      <td>lockdown day</td>\n",
       "      <td>lockdown itali</td>\n",
       "      <td>itali</td>\n",
       "      <td>soon lockdown</td>\n",
       "      <td>soon</td>\n",
       "      <td>mean lockdown</td>\n",
       "      <td>lockdown mean</td>\n",
       "      <td>mean</td>\n",
       "      <td>day guy</td>\n",
       "      <td>play day</td>\n",
       "      <td>guy still</td>\n",
       "      <td>cancel play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 2</th>\n",
       "      <td>peopl</td>\n",
       "      <td>fuck</td>\n",
       "      <td>got</td>\n",
       "      <td>get</td>\n",
       "      <td>shit</td>\n",
       "      <td>act</td>\n",
       "      <td>keep</td>\n",
       "      <td>call</td>\n",
       "      <td>shit got</td>\n",
       "      <td>got peopl</td>\n",
       "      <td>peopl act</td>\n",
       "      <td>work</td>\n",
       "      <td>everi</td>\n",
       "      <td>back</td>\n",
       "      <td>enemi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 3</th>\n",
       "      <td>home</td>\n",
       "      <td>stay</td>\n",
       "      <td>stay home</td>\n",
       "      <td>want</td>\n",
       "      <td>want stay</td>\n",
       "      <td>home vs</td>\n",
       "      <td>forc stay</td>\n",
       "      <td>vs</td>\n",
       "      <td>vs want</td>\n",
       "      <td>forc</td>\n",
       "      <td>nurs</td>\n",
       "      <td>spread</td>\n",
       "      <td>tri</td>\n",
       "      <td>know</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 4</th>\n",
       "      <td>case</td>\n",
       "      <td>confirm</td>\n",
       "      <td>case day</td>\n",
       "      <td>go case</td>\n",
       "      <td>death</td>\n",
       "      <td>day</td>\n",
       "      <td>wonder</td>\n",
       "      <td>case wonder</td>\n",
       "      <td>go</td>\n",
       "      <td>case canada</td>\n",
       "      <td>presumpt</td>\n",
       "      <td>presumpt case</td>\n",
       "      <td>confirm presumpt</td>\n",
       "      <td>report</td>\n",
       "      <td>march case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 5</th>\n",
       "      <td>distanc</td>\n",
       "      <td>social</td>\n",
       "      <td>social distanc</td>\n",
       "      <td>time</td>\n",
       "      <td>us</td>\n",
       "      <td>practic social</td>\n",
       "      <td>practic</td>\n",
       "      <td>bad</td>\n",
       "      <td>mean</td>\n",
       "      <td>popul</td>\n",
       "      <td>infect</td>\n",
       "      <td>quarantin</td>\n",
       "      <td>dead</td>\n",
       "      <td>suck</td>\n",
       "      <td>dickstanc mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 6</th>\n",
       "      <td>like</td>\n",
       "      <td>look</td>\n",
       "      <td>look like</td>\n",
       "      <td>like quarantin</td>\n",
       "      <td>seem like</td>\n",
       "      <td>quarantin</td>\n",
       "      <td>seem</td>\n",
       "      <td>headlin</td>\n",
       "      <td>sound</td>\n",
       "      <td>like headlin</td>\n",
       "      <td>sound like</td>\n",
       "      <td>pass</td>\n",
       "      <td>propos</td>\n",
       "      <td>like pass</td>\n",
       "      <td>propos bill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 7</th>\n",
       "      <td>cancel</td>\n",
       "      <td>everyth except</td>\n",
       "      <td>everyth</td>\n",
       "      <td>cancel everyth</td>\n",
       "      <td>except</td>\n",
       "      <td>weekend</td>\n",
       "      <td>peda weekend</td>\n",
       "      <td>except peda</td>\n",
       "      <td>peda</td>\n",
       "      <td>true</td>\n",
       "      <td>loan</td>\n",
       "      <td>except ptptn</td>\n",
       "      <td>ptptn loan</td>\n",
       "      <td>ptptn</td>\n",
       "      <td>true cancel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 8</th>\n",
       "      <td>say</td>\n",
       "      <td>presid</td>\n",
       "      <td>need</td>\n",
       "      <td>make</td>\n",
       "      <td>american</td>\n",
       "      <td>think</td>\n",
       "      <td>take</td>\n",
       "      <td>anyth</td>\n",
       "      <td>demand</td>\n",
       "      <td>care</td>\n",
       "      <td>crisi</td>\n",
       "      <td>need demand</td>\n",
       "      <td>real</td>\n",
       "      <td>die</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 9</th>\n",
       "      <td>thread</td>\n",
       "      <td>hous</td>\n",
       "      <td>white hous</td>\n",
       "      <td>white</td>\n",
       "      <td>today</td>\n",
       "      <td>bill</td>\n",
       "      <td>dr</td>\n",
       "      <td>fauci</td>\n",
       "      <td>brief</td>\n",
       "      <td>senat</td>\n",
       "      <td>dr fauci</td>\n",
       "      <td>cnn</td>\n",
       "      <td>republican</td>\n",
       "      <td>break</td>\n",
       "      <td>block</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word 0          Word 1          Word 2          Word 3  \\\n",
       "Topic 0      test           posit      test posit           tiger   \n",
       "Topic 1  lockdown             day    day lockdown    lockdown day   \n",
       "Topic 2     peopl            fuck             got             get   \n",
       "Topic 3      home            stay       stay home            want   \n",
       "Topic 4      case         confirm        case day         go case   \n",
       "Topic 5   distanc          social  social distanc            time   \n",
       "Topic 6      like            look       look like  like quarantin   \n",
       "Topic 7    cancel  everyth except         everyth  cancel everyth   \n",
       "Topic 8       say          presid            need            make   \n",
       "Topic 9    thread            hous      white hous           white   \n",
       "\n",
       "                 Word 4          Word 5         Word 6          Word 7  \\\n",
       "Topic 0      tiger test         british        announc  british member   \n",
       "Topic 1  lockdown itali           itali  soon lockdown            soon   \n",
       "Topic 2            shit             act           keep            call   \n",
       "Topic 3       want stay         home vs      forc stay              vs   \n",
       "Topic 4           death             day         wonder     case wonder   \n",
       "Topic 5              us  practic social        practic             bad   \n",
       "Topic 6       seem like       quarantin           seem         headlin   \n",
       "Topic 7          except         weekend   peda weekend     except peda   \n",
       "Topic 8        american           think           take           anyth   \n",
       "Topic 9           today            bill             dr           fauci   \n",
       "\n",
       "                    Word 8           Word 9        Word 10        Word 11  \\\n",
       "Topic 0  member parliament  parliament test  break british     parliament   \n",
       "Topic 1      mean lockdown    lockdown mean           mean        day guy   \n",
       "Topic 2           shit got        got peopl      peopl act           work   \n",
       "Topic 3            vs want             forc           nurs         spread   \n",
       "Topic 4                 go      case canada       presumpt  presumpt case   \n",
       "Topic 5               mean            popul         infect      quarantin   \n",
       "Topic 6              sound     like headlin     sound like           pass   \n",
       "Topic 7               peda             true           loan   except ptptn   \n",
       "Topic 8             demand             care          crisi    need demand   \n",
       "Topic 9              brief            senat       dr fauci            cnn   \n",
       "\n",
       "                  Word 12    Word 13         Word 14  \n",
       "Topic 0            member      first             get  \n",
       "Topic 1          play day  guy still     cancel play  \n",
       "Topic 2             everi       back           enemi  \n",
       "Topic 3               tri       know            live  \n",
       "Topic 4  confirm presumpt     report      march case  \n",
       "Topic 5              dead       suck  dickstanc mean  \n",
       "Topic 6            propos  like pass     propos bill  \n",
       "Topic 7        ptptn loan      ptptn     true cancel  \n",
       "Topic 8              real        die          health  \n",
       "Topic 9        republican      break           block  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show top n keywords for each topic\n",
    "def show_topics(vectorizer, model, n_words):\n",
    "    keywords = np.array(vectorizer.get_feature_names())\n",
    "    topic_keywords = []\n",
    "    for topic_weights in model.components_:\n",
    "        top_keyword_locs = (-topic_weights).argsort()[:n_words]\n",
    "        topic_keywords.append(keywords.take(top_keyword_locs))\n",
    "    return topic_keywords\n",
    "topic_keywords = show_topics(vectorizer, model, 15)\n",
    "# Topic - Keywords Dataframe\n",
    "df_topic_keywords = pd.DataFrame(topic_keywords)\n",
    "df_topic_keywords.columns = ['Word '+str(i) for i in range(df_topic_keywords.shape[1])]\n",
    "df_topic_keywords.index = ['Topic '+str(i) for i in range(df_topic_keywords.shape[0])]\n",
    "df_topic_keywords"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
